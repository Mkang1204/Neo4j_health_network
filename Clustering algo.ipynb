{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /anaconda3/lib/python3.6/site-packages (0.19.1)\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "noisy_circles = datasets.make_circles(n_samples = n_samples, factor = .5, noise =.05)\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "blobs = datasets.make_blobs(n_samples=n_samples,random_state = 8)\n",
    "no_structure = np.random.rand(n_samples, 2), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anisotropicly distributed data\n",
    "random_state = 170\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "transformation = [[0.6, -0.6],[-0.4,0.8]] #?\n",
    "X_aniso = np.dot(X, transformation) #?\n",
    "aniso = (X_aniso, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blobs with varied variances\n",
    "varied = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1512x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#======\n",
    "# set up cluster parameters\n",
    "plt.figure(figsize=(9*2 + 3, 12.5))\n",
    "plt.subplots_adjust(left =.02, right = .98, bottom= .001, top =.96, wspace =.05, hspace = .01)\n",
    "plt_num = 1\n",
    "\n",
    "default_base = {'quatile':3,\n",
    "                'eps':.3,\n",
    "                'damping':.9,\n",
    "               'preference':-200,\n",
    "               'n_neighbors':10,\n",
    "               'n_clusters':3}\n",
    "\n",
    "datasets = [\n",
    "    (noisy_circles, {'damping':.77, 'performance':-240,\n",
    "                    'quantile':.2, 'n_clusters':2}), \n",
    "    (noisy_moons, {'damping':.75 , 'performance': -220, 'n_clusters': 2}),\n",
    "    (varied,{'eps':.18, 'n_neighbors':2}),\n",
    "    (aniso, {'eps':.15, 'n_neighors':2}),\n",
    "    (blobs,{}),\n",
    "    (no_structure, {})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "#     # update parameters with dataset-specific values\n",
    "#     params = default_base.copy()\n",
    "#     params.update(algo_params)\n",
    "    \n",
    "#     X, y = dataset\n",
    "#     X = StandardScaler().fit_transform(X)\n",
    "\n",
    "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "    # update parameters with dataset-specific values\n",
    "    params = default_base.copy()\n",
    "    params.update(algo_params)\n",
    "\n",
    "    X, y = dataset\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # estimate bandwidth for mean shift\n",
    "    connectivity = kneighbors_graph(\n",
    "        X, n_neighbors=params['n_neighbors'], include_self=False)\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5*(connectivity + connectivity.T)\n",
    "    \n",
    "    \n",
    "    #create cluster objects\n",
    "    ms = cluster.MeanShift(bandwidth, bin_seeding=True)\n",
    "    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters)'])\n",
    "    ward = cluster.AgglomerativeClustering(\n",
    "        n_clusters = params['n_clusters'], linkage = 'ward', connectivity = connectivity)\n",
    "    spectral = cluster.SpectralBiclustering(\n",
    "        n_clusters=params['n_clusters'],eigen_colver='arpack', affinity = 'nearest_neighbors')\n",
    "    dbscan = cluster.DBSCAN(eps=params['eps'])\n",
    "    affinity_propagation = cluster.AgglomerativeClustering(\n",
    "        linkage = \"average\". affinity = 'cityblock',\n",
    "        n_cluster = params['n_clusters'], connectivity = connectivity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
